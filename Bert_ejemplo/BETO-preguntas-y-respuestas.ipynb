{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vd82CFhYntkf"},"source":["# BERT : preguntas y respuestas"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Up5yCiniDMEX"},"source":["BERT o Representación de Codificador Bidireccional de Transformadores es una técnica basada en \n","redes neuronales para el pre-entrenamiento del procesamiento del lenguaje natural.\n","\n","El modelo BERT, ya está pre-entrenado para el lenguaje español, y aceptará preguntas que serán respondidas a partir de un texto compartido."]},{"cell_type":"markdown","metadata":{},"source":["Se utilizará HUGGING FACE, que es una librería, que ya posee muchos modelos pre-entrenados (red transformers) para aplicaciones PLN.\n","\n","'mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es'"]},{"cell_type":"markdown","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"colab_type":"code","executionInfo":{"elapsed":4886,"status":"ok","timestamp":1595784561180,"user":{"displayName":"Miguel Sotaquirá","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giuk6OGsE84qo69ZTgJj4B328D6GfU4etVY0q9AUg=s64","userId":"08038952820764930757"},"user_tz":300},"id":"2e2o65JiJ4R-","outputId":"bc5c7883-2a60-433c-aa90-b2e8d517c33a"},"source":["INSTALAMOS LA LIBRERIA:\n","\n","pip install transformers\n","\n","pip3 install torch -> (para AutoModelForQuestionAnswering ) en windows"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":10839,"status":"ok","timestamp":1595784718456,"user":{"displayName":"Miguel Sotaquirá","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giuk6OGsE84qo69ZTgJj4B328D6GfU4etVY0q9AUg=s64","userId":"08038952820764930757"},"user_tz":300},"id":"223xiMP3K9kt"},"outputs":[],"source":["# Importar libreria\n","#AutoTokenizer: Separa el texto con tokens de inicio y final.\n","#AutoModelForQuestionAnswering: Carga del modelo completo.\n","#pipeline: Inferencia con el modelo.\n","\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n","\n","the_model = 'mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es'\n","tokenizer = AutoTokenizer.from_pretrained(the_model, do_lower_case=False)    #False: acepta mayúsculas y minúsculas\n","model = AutoModelForQuestionAnswering.from_pretrained(the_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"tDlFhBfJLj2d"},"outputs":[],"source":["print(model) #mostramos el contenido del MODELO\n","\n","#LA entrada a BERT está definida por un Embedding de 31002 palabras en español y cada una con un vector de 768 elementos.\n","#Final RED NEURONAL con 2 elementos de salida (posición de inicio - posición de salida), respuesta que encontró BERT."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"colab_type":"code","executionInfo":{"elapsed":850,"status":"ok","timestamp":1595785062521,"user":{"displayName":"Miguel Sotaquirá","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giuk6OGsE84qo69ZTgJj4B328D6GfU4etVY0q9AUg=s64","userId":"08038952820764930757"},"user_tz":300},"id":"T2Em_dKRLphz","outputId":"848e7af0-a8ec-4716-9e12-98cfbc3311d3"},"outputs":[],"source":["# Ejemplo tokenización\n","contexto = 'Yo soy Gustavo'\n","pregunta = '¿cómo me llamo?'\n","\n","encode = tokenizer.encode_plus(pregunta, contexto, return_tensors='pt') #codificamos <pregunta> y <contexto>, devuelve valor numérico.\n","input_ids = encode['input_ids'].tolist()\n","tokens = tokenizer.convert_ids_to_tokens(input_ids[0])  #los tokens son las palabras individuales.\n","for id, token in zip(input_ids[0], tokens):\n","  print('{:<12} {:>6}'.format(token, id))   #se imprime el token y la representación numércica\n","  print('')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":2687,"status":"ok","timestamp":1595785279636,"user":{"displayName":"Miguel Sotaquirá","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giuk6OGsE84qo69ZTgJj4B328D6GfU4etVY0q9AUg=s64","userId":"08038952820764930757"},"user_tz":300},"id":"KryC3O2aMnp-","outputId":"5872f450-b17f-4d89-b7f8-308d45744656"},"outputs":[],"source":["# Ejemplo de inferencia (pregunta-respuesta)\n","nlp = pipeline('question-answering', model=model, tokenizer=tokenizer) #indicamos al modelo que tarea queremos que ejecute (pregunta y repuesta)\n","salida = nlp({'question':pregunta, 'context':contexto})\n","print(salida)       #puntaje o probabilidad de la repuesta correcta."]},{"cell_type":"markdown","metadata":{},"source":["AHORA PROBAREMOS CON UN TEXTO MAS EXTENSO."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":1007,"status":"ok","timestamp":1595785561057,"user":{"displayName":"Miguel Sotaquirá","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giuk6OGsE84qo69ZTgJj4B328D6GfU4etVY0q9AUg=s64","userId":"08038952820764930757"},"user_tz":300},"id":"XA6f0-DYNu2L"},"outputs":[],"source":["from textwrap import wrap        #ajuste de texto a ancho de pantalla\n","\n","def pregunta_respuesta(model, contexto, nlp):     #creamos función\n","\n","  # Imprimir contexto\n","  print('Contexto:')\n","  print('-----------------')\n","  print('\\n'.join(wrap(contexto)))\n","\n","  # Loop preguntas-respuestas:          para varias preguntas y repuestas. Si está VACÍA -> TERMINA\n","  continuar = True\n","  while continuar:\n","    print('\\nPregunta:')\n","    print('-----------------')\n","    pregunta = str(input())            #entrada de pregunta por teclado, se convierte a string\n","\n","    continuar = pregunta!=''\n","\n","    if continuar:\n","      salida = nlp({'question':pregunta, 'context':contexto})\n","      print('\\nRespuesta:')\n","      print('-----------------')\n","      print(salida['answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"colab_type":"code","executionInfo":{"elapsed":16749,"status":"ok","timestamp":1595785603206,"user":{"displayName":"Miguel Sotaquirá","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giuk6OGsE84qo69ZTgJj4B328D6GfU4etVY0q9AUg=s64","userId":"08038952820764930757"},"user_tz":300},"id":"64bUn-bnOz9b","outputId":"9d254f27-7189-4c91-b339-f0bd48378249"},"outputs":[],"source":["pregunta_respuesta(model, contexto, nlp)"]},{"cell_type":"markdown","metadata":{},"source":["CARGAMOS UN PÁRRAFO DE TEXTO Y HACEMOS PREGUNTAS BASADAS EN ÉL."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","id":"qSq3FUAxO6aJ","outputId":"f31dcf30-b708-40b0-b0ed-7582427e9f45"},"outputs":[],"source":["contexto = \"Tesla, que nació y se crio en el Imperio austríaco, estudió ingeniería y física en la década de 1870 sin obtener un título, aunque adquirió experiencia práctica a principios de la década de 1880 trabajando en telefonía para la empresa Continental Edison, que por entonces lideraba la nueva industria de la energía eléctrica. En 1884 emigró a Estados Unidos, donde adquirió la doble nacionalidad. Trabajó durante un corto tiempo en Edison Machine Works en Nueva York antes de emprender el camino por su cuenta. Con la ayuda de socios para financiar y comercializar sus ideas, Tesla fundó laboratorios y empresas en Nueva York para desarrollar dispositivos eléctricos y mecánicos. Su motor asíncrono de corriente alterna (CA) y las patentes relacionadas con el sistema polifásico, licenciadas por Westinghouse Electric en 1888, le reportaron grandes sumas de dinero y además se convirtieron en la piedra angular del sistema polifásico finalmente comercializado por esta empresa.\"\n","pregunta_respuesta(model, contexto, nlp)"]},{"cell_type":"markdown","metadata":{},"source":["REEMPLAZAR EL TEXTO, DE LA CELDA ANTERIOR, Y REALIZAR DISTINTAS PREGUNTAS.\n","NO NECESARIAMENTE, LAS PALABRAS A UTILIZAR PARA REALIZAR LAS PREGUNTAS, DEBEN ENCONTRARSE EN EL TEXTO !!!"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNu+nbGJl9A+EjbN/vsrJfD","collapsed_sections":[],"name":"BETO-preguntas-y-respuestas.ipynb","provenance":[{"file_id":"1n1JS7UjVunywz8O2lyhbOfTyW_HmbNi6","timestamp":1595779968724},{"file_id":"1xQM35HoJo8iU54v3HclQ7tjWr1-zavIc","timestamp":1595327472396}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
