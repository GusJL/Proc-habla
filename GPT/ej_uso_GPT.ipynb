{"cells":[{"cell_type":"markdown","metadata":{"id":"13877tD3TxCN"},"source":["## uso de la API de OpenAI"]},{"cell_type":"markdown","metadata":{"id":"Xky3yk53SGXQ"},"source":["Instalar librería de OpenAI\n","\n","pip install openai"]},{"cell_type":"markdown","metadata":{"id":"-chXGqykT19o"},"source":["## Importar librerías"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yda6XTJ2Tiz7"},"outputs":[],"source":["from openai import OpenAI"]},{"cell_type":"markdown","metadata":{},"source":["1)_ ES NECESARIO TENER UNA CUENTA DE OpenAI\n","    A)_ Login\n","    B)_ API\n","    C)_ Perfil\n","            * Manager account\n","    D)_ Billing overview (cuenta libre \"limitado\" o de pago **ver)\n","2)_ Generar la api_key:\n","    A)_ Perfil\n","            * View API key\n","            * Create new secret key \"\"INFORMACIÓN PRIVADA, SE MUESTRA 1 VEZ\"\""]},{"cell_type":"markdown","metadata":{"id":"rlk32AjFT6KU"},"source":["## Cargar API Key de OpenAI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sHehHPGPT_iS"},"outputs":[],"source":["key='Ingresa aquí tu API Key de OpenAI'\n","openai.api_key = key"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["modelo = 'gpt-3.5-turbo'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAydwHmcRcfn"},"outputs":[],"source":["prompt = 'Cuál es la capital de Argentina'\n","\n","#El primer rol de sistema: \"es el contexto\"\n","#El segundo rol de usuario: \"contenido\" -> es el =prompt\n","\n","mensajes = [{'role':'system', 'content': 'dame una repuesta de al menos 3 líneas'},{'role':'user', 'content':prompt}]\n","\n","#**probar con estas líneas:\n","#mensajes = [{'role':'system', 'content': 'dame una repuesta de media línea'},{'role':'user', 'content':prompt}]\n","#mensajes = [{'role':'system', 'content': 'dame una repuesta corta'},{'role':'user', 'content':prompt}]\n","\n","#temperatura= \"nivel de creatividad (máx=1)\"\n","#max_tokens= \"cantiad de tokens máximo\"\n","\n","respuesta = openai.ChatCompletion.create(model = modelo, messages = mensajes, temperature = 0.8, max_tokens = 1000)\n","\n","print(respuesta)\n","\n","#luego probar con \"la siguiente línea\", para obtener una repuesta mas específica de los datos recividos\n","#print(respuesta[\"choices\"][0][\"mesaje\"][\"content\"])"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
